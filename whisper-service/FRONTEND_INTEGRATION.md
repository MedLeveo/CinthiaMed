# üé§ Integra√ß√£o do Frontend com o Servi√ßo de Voz

Este guia mostra como integrar o sistema de transcri√ß√£o de voz no frontend React do CinthiaMed.

---

## üìã Configura√ß√£o Inicial

### 1. Adicionar vari√°vel de ambiente

Crie ou edite o arquivo `.env` no root do projeto React:

```env
# URL do servi√ßo de voz na VPS
REACT_APP_VOICE_SERVICE_URL=https://voice.cinthiamed.com.br
# ou durante desenvolvimento:
# REACT_APP_VOICE_SERVICE_URL=http://localhost:8000
```

---

## üéØ Componente de Grava√ß√£o de √Åudio

Crie o arquivo `src/components/VoiceRecorder.jsx`:

```jsx
import React, { useState, useRef } from 'react';
import './VoiceRecorder.css';

const VoiceRecorder = ({ onTranscription }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [error, setError] = useState(null);

  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);

  // Iniciar grava√ß√£o
  const startRecording = async () => {
    try {
      setError(null);

      // Solicitar permiss√£o do microfone
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000, // Whisper funciona bem com 16kHz
          echoCancellation: true,
          noiseSuppression: true,
        }
      });

      // Configurar MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      // Coletar chunks de √°udio
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      // Quando parar a grava√ß√£o
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
        await sendAudioForTranscription(audioBlob);

        // Parar todas as tracks
        stream.getTracks().forEach(track => track.stop());
      };

      // Iniciar grava√ß√£o
      mediaRecorder.start();
      setIsRecording(true);

    } catch (err) {
      console.error('Erro ao iniciar grava√ß√£o:', err);
      setError('N√£o foi poss√≠vel acessar o microfone. Verifique as permiss√µes.');
    }
  };

  // Parar grava√ß√£o
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  // Enviar √°udio para transcri√ß√£o
  const sendAudioForTranscription = async (audioBlob) => {
    setIsProcessing(true);
    setError(null);

    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      formData.append('language', 'pt');

      const response = await fetch(
        `${process.env.REACT_APP_VOICE_SERVICE_URL}/transcribe`,
        {
          method: 'POST',
          body: formData,
        }
      );

      if (!response.ok) {
        throw new Error(`Erro na transcri√ß√£o: ${response.status}`);
      }

      const result = await response.json();

      // Callback com o texto transcrito
      if (onTranscription) {
        onTranscription(result.text);
      }

    } catch (err) {
      console.error('Erro na transcri√ß√£o:', err);
      setError('Erro ao processar o √°udio. Tente novamente.');
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div className="voice-recorder">
      <button
        className={`voice-button ${isRecording ? 'recording' : ''}`}
        onClick={isRecording ? stopRecording : startRecording}
        disabled={isProcessing}
      >
        {isProcessing ? (
          <>
            <span className="spinner"></span>
            Processando...
          </>
        ) : isRecording ? (
          <>
            <span className="recording-indicator"></span>
            Parar Grava√ß√£o
          </>
        ) : (
          <>
            <span className="mic-icon">üé§</span>
            Gravar √Åudio
          </>
        )}
      </button>

      {error && (
        <div className="error-message">
          ‚ö†Ô∏è {error}
        </div>
      )}
    </div>
  );
};

export default VoiceRecorder;
```

---

## üé® CSS do Componente

Crie `src/components/VoiceRecorder.css`:

```css
.voice-recorder {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 1rem;
}

.voice-button {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 1rem 2rem;
  font-size: 1rem;
  font-weight: 600;
  border: none;
  border-radius: 50px;
  cursor: pointer;
  transition: all 0.3s ease;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
}

.voice-button:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
}

.voice-button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

.voice-button.recording {
  background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
  animation: pulse 1.5s ease-in-out infinite;
}

@keyframes pulse {
  0%, 100% {
    box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
  }
  50% {
    box-shadow: 0 6px 25px rgba(245, 87, 108, 0.8);
  }
}

.recording-indicator {
  width: 12px;
  height: 12px;
  background-color: #ff4444;
  border-radius: 50%;
  animation: blink 1s ease-in-out infinite;
}

@keyframes blink {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.3; }
}

.spinner {
  width: 16px;
  height: 16px;
  border: 3px solid rgba(255, 255, 255, 0.3);
  border-top-color: white;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  to { transform: rotate(360deg); }
}

.mic-icon {
  font-size: 1.2rem;
}

.error-message {
  padding: 0.75rem 1.5rem;
  background-color: #fee;
  color: #c33;
  border-radius: 8px;
  font-size: 0.9rem;
  text-align: center;
}
```

---

## üîó Integra√ß√£o no Chat

Exemplo de como usar no componente de chat principal:

```jsx
import React, { useState } from 'react';
import VoiceRecorder from './components/VoiceRecorder';

function ChatPage() {
  const [message, setMessage] = useState('');

  // Callback quando a transcri√ß√£o estiver pronta
  const handleTranscription = (text) => {
    console.log('Texto transcrito:', text);

    // Adicionar o texto transcrito ao input
    setMessage(prevMessage => prevMessage + ' ' + text);

    // OU enviar automaticamente para a IA
    // sendMessageToAI(text);
  };

  return (
    <div className="chat-container">
      {/* ... resto do chat ... */}

      <div className="input-area">
        <textarea
          value={message}
          onChange={(e) => setMessage(e.target.value)}
          placeholder="Digite sua mensagem ou use o bot√£o de voz..."
        />

        <div className="actions">
          <VoiceRecorder onTranscription={handleTranscription} />

          <button onClick={() => sendMessage(message)}>
            Enviar
          </button>
        </div>
      </div>
    </div>
  );
}

export default ChatPage;
```

---

## üéØ Vers√£o Simplificada (Apenas Texto)

Se voc√™ quer apenas pegar o texto sem componente visual:

```jsx
// Fun√ß√£o utilit√°ria para transcrever √°udio
export async function transcribeAudio(audioBlob) {
  const formData = new FormData();
  formData.append('audio', audioBlob, 'recording.webm');
  formData.append('language', 'pt');

  const response = await fetch(
    `${process.env.REACT_APP_VOICE_SERVICE_URL}/transcribe-streaming`,
    {
      method: 'POST',
      body: formData,
    }
  );

  if (!response.ok) {
    throw new Error(`Transcri√ß√£o falhou: ${response.status}`);
  }

  const result = await response.json();
  return result.text;
}

// Uso:
const text = await transcribeAudio(audioBlob);
console.log('Transcri√ß√£o:', text);
```

---

## üöÄ Uso Avan√ßado: Upload de Arquivo

Para permitir que o usu√°rio envie um arquivo de √°udio gravado:

```jsx
const FileUploadTranscriber = ({ onTranscription }) => {
  const [isProcessing, setIsProcessing] = useState(false);

  const handleFileUpload = async (event) => {
    const file = event.target.files[0];
    if (!file) return;

    // Verificar tamanho (m√°x 25MB)
    if (file.size > 25 * 1024 * 1024) {
      alert('Arquivo muito grande! M√°ximo: 25MB');
      return;
    }

    setIsProcessing(true);

    try {
      const formData = new FormData();
      formData.append('audio', file);
      formData.append('language', 'pt');

      const response = await fetch(
        `${process.env.REACT_APP_VOICE_SERVICE_URL}/transcribe`,
        {
          method: 'POST',
          body: formData,
        }
      );

      const result = await response.json();
      onTranscription(result.text);

    } catch (error) {
      console.error('Erro:', error);
      alert('Erro ao processar √°udio');
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div>
      <input
        type="file"
        accept="audio/*"
        onChange={handleFileUpload}
        disabled={isProcessing}
        style={{ display: 'none' }}
        id="audio-upload"
      />
      <label htmlFor="audio-upload" className="upload-button">
        {isProcessing ? 'Processando...' : 'üìé Upload de √Åudio'}
      </label>
    </div>
  );
};
```

---

## üîê Tratamento de Erros

Sempre adicione tratamento de erros adequado:

```jsx
const handleTranscriptionWithErrorHandling = async (audioBlob) => {
  try {
    const response = await fetch(
      `${process.env.REACT_APP_VOICE_SERVICE_URL}/transcribe`,
      {
        method: 'POST',
        body: formData,
      }
    );

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.detail || 'Erro desconhecido');
    }

    const result = await response.json();
    return result.text;

  } catch (error) {
    // Tratar diferentes tipos de erro
    if (error.message.includes('Failed to fetch')) {
      alert('Servi√ßo de voz est√° offline. Tente novamente mais tarde.');
    } else if (error.message.includes('muito grande')) {
      alert('√Åudio muito longo. Grave menos de 2 minutos.');
    } else {
      alert(`Erro na transcri√ß√£o: ${error.message}`);
    }

    throw error;
  }
};
```

---

## üì± Suporte Mobile

O c√≥digo acima funciona em mobile! Apenas certifique-se:

1. **HTTPS obrigat√≥rio**: Navegadores mobile exigem HTTPS para acessar microfone
2. **Permiss√µes**: O usu√°rio precisar√° aceitar permiss√£o do microfone
3. **Tamanho do bot√£o**: Use tamanhos maiores de bot√£o para touch

```css
@media (max-width: 768px) {
  .voice-button {
    padding: 1.2rem 2.5rem;
    font-size: 1.1rem;
  }
}
```

---

## üéØ Pr√≥ximos Passos

1. **Feedback visual**: Mostre forma de onda durante grava√ß√£o
2. **S√≠ntese de voz (TTS)**: Ler respostas da IA em voz alta
3. **Hist√≥rico**: Salvar transcri√ß√µes para consulta
4. **Offline**: Implementar fallback quando servi√ßo estiver offline

---

## üí° Dicas de UX

- **Instru√ß√µes claras**: Mostre ao usu√°rio que ele pode usar voz
- **Feedback imediato**: Indique quando est√° gravando/processando
- **Fallback**: Sempre deixe op√ß√£o de digitar manualmente
- **Privacidade**: Informe que o √°udio √© processado na sua VPS

---

**Desenvolvido para CinthiaMed** üè•
